{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4b0f3c",
   "metadata": {},
   "source": [
    "<h1>Hyperparameter Exploration</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics  \n",
    "from sklearn import ensemble\n",
    "\n",
    "# For reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "r_state = 42\n",
    "random.seed(r_state) \n",
    "np.random.seed(r_state)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import datetime\n",
    "\n",
    "# Needed on a Mac\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac84b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_status_scores(dtype):\n",
    "    status = pd.read_csv('/Users/ritalaplante/Desktop/Thesis Data and Analytics/04-Neighborhood Scores/scores' + to_use + '.csv', index_col=0)  # SES scores\n",
    "    \n",
    "    status.dropna(inplace = True)\n",
    "    \n",
    "    # Scores\n",
    "    status.drop(['RANK_10','RANK_19'], axis=1, inplace=True)\n",
    "    status.rename(columns={\n",
    "        'SES_10':'SES 2010',\n",
    "        'SES_19':'SES 2019',\n",
    "        'SES_ASC':'SES Ascent 2010-2019',\n",
    "        'SES_PR_10':'SES 2010 Percentile', # 99 = High-status\n",
    "        'SES_PR_19':'SES 2019 Percentile', # 99 = High-status\n",
    "        'SES_PR_ASC':'SES Percentile Ascent 2010-2019'\n",
    "    }, inplace=True)\n",
    "    return status\n",
    "\n",
    "def classifier_report(clf, y_true, y_hat):\n",
    "    \n",
    "    txt = ''\n",
    "    \n",
    "    # If the task is regression evaluate using regression metrics, \n",
    "    # otherwise evaluate using classification metrics\n",
    "    txt += \"R2:        {0:8.5f}\".format(metrics.r2_score(y_true, y_hat)) + \"\\n\" #  R2 - Coefficient of determination\n",
    "    txt += \"MSE:       {0:8.5f}\".format(metrics.mean_squared_error(y_true, y_hat)) + \"\\n\"  #  Mean squared error regression loss\n",
    "    txt += \"MAE:       {0:8.5f}\".format(metrics.mean_absolute_error(y_true, y_hat)) + \"\\n\"  #  Mean absolute error regression loss\n",
    "    txt += \"Expl. Var: {0:8.5f}\".format(metrics.explained_variance_score(y_true, y_hat)) + \"\\n\"  # Explained variance regression score function\n",
    "    txt += \"\\n\"\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5195ea",
   "metadata": {},
   "source": [
    "<h2>Exploring Hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a paramter grid and explore a hyperparameter space\n",
    "# using Cross-Fold Validation...\n",
    "def explore_extr_hyper(params, x_train, y_train):\n",
    "    \n",
    "    clf = ensemble.ExtraTreesRegressor(n_jobs=-1, random_state=r_state)\n",
    "    cv  = model_selection.GridSearchCV(estimator=clf, param_grid=params, cv=4, n_jobs=2, \n",
    "                                       return_train_score=True, verbose=1, scoring='neg_mean_absolute_error') \n",
    "\n",
    "    cv.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best score: \" + str(cv.best_score_))\n",
    "    print(\"Best parameters: \" + str(cv.best_params_))\n",
    "    \n",
    "    best_clf = cv.best_estimator_ # Extract the best estimator from the GridSearch\n",
    "    best_clf.fit(x_train, y_train)\n",
    "    y_pred  = best_clf.predict(X_test)\n",
    "\n",
    "    print(classifier_report(best_clf, y_test, y_pred))\n",
    "    return cv\n",
    "\n",
    "# Output the results of a Cross-Validation process\n",
    "# to a data frame. Currently focussed on training and\n",
    "# testing scores.\n",
    "def cv_to_df(cvr):\n",
    "    # Extract the parameters from the Cross-Validation object that \n",
    "    # we want to track in our results\n",
    "    params  = cvr.cv_results_['params']\n",
    "    trn_scr = cvr.cv_results_['mean_train_score']\n",
    "    tst_scr = cvr.cv_results_['mean_test_score']\n",
    "    trn_std = cvr.cv_results_['std_train_score']\n",
    "    tst_std = cvr.cv_results_['std_test_score']\n",
    "    rank    = cvr.cv_results_['rank_test_score']\n",
    "    \n",
    "    # Create a data frame from the numbers\n",
    "    df = pd.DataFrame.from_dict({'Training Score':trn_scr, 'Test Score':tst_scr, \n",
    "                                'Std. of Training Scores':trn_std, 'Std. of Test Scores':tst_std})\n",
    "    \n",
    "    # Add the rank of the result\n",
    "    rs = pd.Series(rank, index=df.index)\n",
    "    df['rank'] = rs\n",
    "    \n",
    "    # And now work out how many parameters there\n",
    "    # were and create the appropriate columns to\n",
    "    # add to the df. Start with named parameters...\n",
    "    n_params = cvr.cv_results_['params'][0].keys()\n",
    "    \n",
    "    # Convert these to arrays that can be assigned\n",
    "    # as a new data series to the df.\n",
    "    for p in list(n_params):\n",
    "        vals = []\n",
    "        for v in cvr.cv_results_['params']:\n",
    "            vals.append(v[p])\n",
    "        \n",
    "        # Create and assign a new series using\n",
    "        # the index from the data frame to avoid\n",
    "        # setting-with-copy warnings\n",
    "        ps = pd.Series(vals, index=df.index)\n",
    "        df[p] = ps\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can override to_use here if have already generated data above\n",
    "to_use = 'Untransformed'\n",
    "\n",
    "SES = load_status_scores(to_use)  # SES scores in 2011\n",
    "\n",
    "#  Read the transformed data\n",
    "d10_trs2 = pd.read_csv('/Users/ritalaplante/Desktop/Thesis Data and Analytics/05-Transformed and Scaled Data/TransformedAndScaled2010' + to_use + '.csv', index_col=0)\n",
    "d19_trs2 = pd.read_csv('/Users/ritalaplante/Desktop/Thesis Data and Analytics/05-Transformed and Scaled Data/TransformedAndScaled2019' + to_use + '.csv', index_col=0)\n",
    "\n",
    "# # Data about variables used later in process\n",
    "# vardb = pd.read_csv(os.path.join('data','variables.csv'), index_col=False)\n",
    "# vardb.drop('Description', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d10_trs2.fillna(0, inplace = True)\n",
    "SES.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288560b",
   "metadata": {},
   "source": [
    "<p>Split the dataset into testing and training where the test set size is 20%</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183dfd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    d10_trs2, SES['SES Ascent 2010-2019'], test_size=0.2, random_state=r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e07a2",
   "metadata": {},
   "source": [
    "<h2>n_estimators</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40aafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\" : [int(x) for x in np.arange(start=20, stop=2001, step=20)]\n",
    "}\n",
    "\n",
    "start = timer()\n",
    "cv1 = explore_extr_hyper(param_grid, X_train, y_train)\n",
    "duration = timer() - start\n",
    "print(\"Execution complete in: {0:15.1f}s\".format(duration) + \" (\" + str(datetime.timedelta(seconds=duration)) + \")\")\n",
    "\n",
    "cv_to_df(cv1).to_csv('/Users/ritalaplante/Desktop/Thesis Data and Analytics/06-Hyperparameter Results/' + to_use + '-Scores-n_estimators.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a1381",
   "metadata": {},
   "source": [
    "<p>Fitting 4 folds for each of 100 candidates, totalling 400 fits <br>\n",
    "Best score: -0.34136118333074356 <br>\n",
    "Best parameters: {'n_estimators': 140}<br>\n",
    "R2:         0.51562<br>\n",
    "MSE:        0.17629<br>\n",
    "MAE:        0.32551<br>\n",
    "Expl. Var:  0.51792<br>\n",
    "\n",
    "\n",
    "Execution complete in:           951.6s (0:15:51.591884)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b09278",
   "metadata": {},
   "source": [
    "<h2>max_depth</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\" : [int(x) for x in np.arange(start=10, stop=161, step=10)],\n",
    "}\n",
    "\n",
    "start = timer()\n",
    "cv2 = explore_extr_hyper(param_grid, X_train, y_train)\n",
    "duration = timer() - start\n",
    "print(\"Execution complete in: {0:15.1f}s\".format(duration) + \" (\" + str(datetime.timedelta(seconds=duration)) + \")\")\n",
    "\n",
    "cv_to_df(cv2).to_csv('/Users/ritalaplante/Desktop/Thesis Data and Analytics/06-Hyperparameter Results/' + to_use + '-Scores-max_depth.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4136175",
   "metadata": {},
   "source": [
    "<p>Fitting 4 folds for each of 16 candidates, totalling 64 fits<br>\n",
    "Best score: -0.34289399061295284<br>\n",
    "Best parameters: {'max_depth': 120}<br>\n",
    "R2:         0.51194<br>\n",
    "MSE:        0.17763<br>\n",
    "MAE:        0.32866<br>\n",
    "Expl. Var:  0.51453<br>\n",
    "\n",
    "\n",
    "Execution complete in:            19.5s (0:00:19.544697)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4593ba",
   "metadata": {},
   "source": [
    "<h2>min_samples_leaf</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d00c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"min_samples_leaf\" : [int(x) for x in np.arange(start=1, stop=26, step=1)],\n",
    "}\n",
    "\n",
    "start = timer()\n",
    "cv3 = explore_extr_hyper(param_grid, X_train, y_train)\n",
    "duration = timer() - start\n",
    "print(\"Execution complete in: {0:15.1f}s\".format(duration) + \" (\" + str(datetime.timedelta(seconds=duration)) + \")\")\n",
    "\n",
    "# Save results to CSV file\n",
    "cv_to_df(cv3).to_csv('/Users/ritalaplante/Desktop/Thesis Data and Analytics/06-Hyperparameter Results/' + to_use + '-Scores-min_samples_leaf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b5eda",
   "metadata": {},
   "source": [
    "<p>Fitting 4 folds for each of 25 candidates, totalling 100 fits<br>\n",
    "Best score: -0.34216994251968924<br>\n",
    "Best parameters: {'min_samples_leaf': 3}<br>\n",
    "R2:         0.52231<br>\n",
    "MSE:        0.17385<br>\n",
    "MAE:        0.32741<br>\n",
    "Expl. Var:  0.52351<br>\n",
    "\n",
    "\n",
    "Execution complete in:            14.5s (0:00:14.508016)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2bae3",
   "metadata": {},
   "source": [
    "<h2>max_features and bootstrap</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_features\"  : [float(x) for x in np.arange(start=0.1, stop=1.01, step=0.1)], # For regression normally n_features (worth trying after shorter runs)\n",
    "    \"bootstrap\"     : [True, False]    # Not normally needed for ExtraTrees, but seems to improve performance?\n",
    "}\n",
    "\n",
    "param_grid['max_features'].append('auto')\n",
    "param_grid['max_features'].append('sqrt')\n",
    "\n",
    "start = timer()\n",
    "cv4 = explore_extr_hyper(param_grid, X_train, y_train)\n",
    "duration = timer() - start\n",
    "print(\"Execution complete in: {0:15.1f}s\".format(duration) + \" (\" + str(datetime.timedelta(seconds=duration)) + \")\")\n",
    "\n",
    "# Save results to CSV file\n",
    "cv_to_df(cv4).to_csv('/Users/ritalaplante/Desktop/Thesis Data and Analytics/06-Hyperparameter Results/' + to_use + '-Scores-max_features_and_bootstrap.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0d9a7",
   "metadata": {},
   "source": [
    "<p>Fitting 4 folds for each of 24 candidates, totalling 96 fits<br>\n",
    "Best score: -0.34217298840233246<br>\n",
    "Best parameters: {'bootstrap': False, 'max_features': 0.5}<br>\n",
    "R2:         0.53018<br>\n",
    "MSE:        0.17099<br>\n",
    "MAE:        0.32363<br>\n",
    "Expl. Var:  0.53210<br>\n",
    "\n",
    "\n",
    "Execution complete in:            14.6s (0:00:14.599733)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e41221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
